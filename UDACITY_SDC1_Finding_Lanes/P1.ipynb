{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "\n",
    "## Project: **Finding Lane Lines on the Road** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lane Detection Results**\n",
    "\n",
    "---\n",
    "\n",
    "<figure>\n",
    " <img src=\"test_images/solidWhiteCurve.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Before Lane Detection </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"(6)result.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> After Lane Detection</p> \n",
    " </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "Video = './test_videos/solidYellowLeft.mp4'\n",
    "cap =  cv2.VideoCapture(Video) #Read Video\n",
    "\n",
    "# Setting for saving image\n",
    "fps = 30.0\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "fcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('output.avi', fcc, fps, (width,height))\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "\n",
    "\n",
    "    if ret:\n",
    "        \n",
    "        #Read in and grayscale the image\n",
    "        gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)   \n",
    "        \n",
    "        #Define a kernel size and apply Gaussian smoothing\n",
    "        kernel_size = 5\n",
    "        blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)\n",
    "        \n",
    "        #Define our parameters for Canny and Apply\n",
    "        low_threshold = 50\n",
    "        high_threshold = 150\n",
    "        edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "        \n",
    "        #Create masked edges image using cv2.fillPoly()\n",
    "        mask = np.zeros_like(edges)\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "        #Define four-side polygon to mask\n",
    "        imshape = image.shape\n",
    "        vertices = np.array([[(0,imshape[0]),(imshape[1]//2-10,imshape[0]//2+47),\n",
    "                      (imshape[1]//2+10,imshape[0]//2+47), (imshape[1],imshape[0])]], dtype=np.int32)\n",
    "        cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "        masked_edges = cv2.bitwise_and(edges, mask)   \n",
    "\n",
    "        \n",
    "        # Define the Hough transform parameters\n",
    "        rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "        threshold = 1                 # minimum number of votes (intersections in Hough grid cell)\n",
    "        min_line_length = 152          # minimum number of pixels making up a line\n",
    "        max_line_gap = 100             # maximum gap in pixels between connectable line segments\n",
    "        line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "\n",
    "        # Hough Transform on masked_edges\n",
    "        lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "        \n",
    "        # Draw Hough Transformed line on blank image\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "        # Create a \"color\" binary image to combine with line image\n",
    "        color_edges = np.dstack((edges, edges, edges))\n",
    "\n",
    "        # Add line image on original image\n",
    "        result = cv2.add(image,line_image)\n",
    "\n",
    "        \n",
    "        # Show results\n",
    "        cv2.imshow('video',result)\n",
    "\n",
    "        # Save results in Video\n",
    "        out.write(result)        \n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`import numpy as np`\n",
    " <p></p>\n",
    "`import cv2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Setup for Video Reading & Writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "videopath = './test_videos/solidWhiteRight.mp4'\n",
    "cap =  cv2.VideoCapture(videopath) \n",
    "\n",
    "fps = 30.0\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "fcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "out = cv2.VideoWriter('output.avi', fcc, fps, (width,height))\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()    \n",
    "    \n",
    "    if ret:        \n",
    "        \n",
    "        #####################################    \n",
    "        ###########MAIN CODE PART############\n",
    "        #####################################\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Original Image -> Gray scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change into gray scale**\n",
    " <p></p>\n",
    "`gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)`\n",
    "\n",
    "**Change into blur_gray scale**\n",
    " <p></p>\n",
    "`kernel_size = 5 \n",
    "blur_gray = cv2.GaussianBlur(gray,(kernel_size, kernel_size),0)`\n",
    " <p></p>\n",
    "\n",
    "<figure>\n",
    " <img src=\"(1)gray.jpg\" width=\"300\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Gray </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    " <p></p> \n",
    "<figure>\n",
    " <img src=\"(2)blur_gray.jpg\" width=\"300\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Blurred Gray </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Gray Image -> Canny Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change into Canny Edge Detection**\n",
    "\n",
    "`low_threshold = 50\n",
    "high_threshold = 150\n",
    "edges = cv2.Canny(blur_gray, low_threshold, high_threshold)`\n",
    " <p></p> \n",
    " \n",
    "<figure>\n",
    " <img src=\"(3)Cannyedges.jpg\" width=\"300\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Canny Edge </p> \n",
    " </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Mask and Filter**\n",
    "\n",
    "`mask = np.zeros_like(edges)\n",
    "ignore_mask_color = 255       \n",
    "imshape = image.shape\n",
    "vertices = np.array([[(0,imshape[0]),(imshape[1]//2-20,imshape[0]//2+50), (imshape[1]//2+20,imshape[0]//2+50), (imshape[1],imshape[0])]], type=np.int32)\n",
    "cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "masked_edges = cv2.bitwise_and(edges, mask)  `\n",
    " <p></p> \n",
    " \n",
    "<figure>\n",
    " <img src=\"(4)masked_edges.jpg\" width=\"300\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    "     <p style=\"text-align: center;\"> Canny Edge with Mask </p>\n",
    " </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [6] Hough Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Parameters**\n",
    " <p></p>\n",
    "`rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "threshold = 1                 # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 40          # minimum number of pixels making up a line\n",
    "max_line_gap = 20             # maximum gap in pixels between connectable line segments`\n",
    "\n",
    "**Run Hough Transform and Draw Lines**\n",
    " <p></p>\n",
    "`line_image = np.copy(image)\n",
    "lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)`\n",
    " <p></p>\n",
    " \n",
    "<figure>\n",
    " <img src=\"(5)line_image.jpg\" width=\"300\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    "     <p style=\"text-align: center;\"> Line Image with Hough Transform </p>\n",
    " </figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7] RESULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Image + Line Image**\n",
    " <p></p>\n",
    "`result = cv2.add(image,line_image)`\n",
    " \n",
    "<figure>\n",
    " <img src=\"(6)result.jpg\" width=\"380\" alt=\"Combined Image\" />\n",
    " <figcaption>\n",
    " <p></p> \n",
    "     <p style=\"text-align: center;\"> Line Detection Result </p>\n",
    " </figcaption>\n",
    "</figure>\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
